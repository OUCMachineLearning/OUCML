# æ·±å…¥ç†è§£é£æ ¼è¿ç§»ä¸‰éƒ¨æ›²(ä¸‰)--FUNIT

æ ‡ç­¾ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼š é™ˆæ‰¬

---

> FUNIT: Few-Shot Unsupervised Image-to-Image Translation
>
> project:https://nvlabs.github.io/FUNIT/
>
> ä½œè€…:[é™ˆæ‰¬](https://www.zhihu.com/people/ba-la-ba-la-82-47/activities)

[toc]

## ç®€ä»‹

æ— ç›‘ç£çš„å›¾åƒåˆ°å›¾åƒè½¬æ¢æ–¹æ³•å­¦ä¹ åˆ©ç”¨å›¾åƒçš„éç»“æ„åŒ–(UNlabel)æ•°æ®é›†å°†ç»™å®šç±»ä¸­çš„å›¾åƒæ˜ å°„åˆ°ä¸åŒç±»ä¸­çš„ç±»ä¼¼å›¾åƒã€‚åœ¨ICCV2019ä¸Š,NVIDIA-Labå‘è¡¨äº†Image-to-imageæœ€æ–°çš„ç ”ç©¶æˆæœ,åŸºäºå°‘é‡ç±»åˆ«å­¦ä¹ çš„FUNIT.ç¬”è€…åœ¨CVPR2020çš„æŠ•ç¨¿ä¸­æ­£å¥½ä¹Ÿå¤§é‡æ¶‰åŠåˆ°äº†image2imageçš„å®éªŒ,å…¶ä¸­æ ·æœ¬ä¸å‡è¡¡æ˜¯å¯¹unpair-image2imageä»»åŠ¡æ¥è¯´åŒæ ·æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„é—®é¢˜,è€Œfew-shot Learningåˆ™æ˜¯å…¶ä¸­ä¸€ç§æç«¯æƒ…å†µ.äºæ­¤åŒæ—¶,paperä¸­ä»¤æˆ‘å½±å“æ·±åˆ»çš„æ˜¯ä½œè€…åšäº†å¤§é‡çš„Ablation Study ,å……åˆ†çš„å®éªŒè¯æ˜äº†ç®—æ³•çš„æœ‰æ•ˆæ€§ä»¥åŠé²æ£’æ€§.

---

## å‰è¨€

åœ¨æˆ‘ä»¬å±•å¼€æ·±å…¥ç†è§£FUNITä¹‹å‰,æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ä»–çš„å‰èº«UNIT,ç”±NVIDIA-Labåœ¨2017å¹´æå‡º,è¯¥æ–‡ç« é¦–æ¬¡æImage-Image Translationè¿™ä¸ªæ¦‚å¿µï¼Œå°†è®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦çš„è®¸å¤šä»»åŠ¡æ€»ç»“è¿›å»ï¼Œåˆ†ä¸ºä¸€å¯¹å¤šå’Œå¤šå¯¹ä¸€çš„ä¸¤ç±»è½¬æ¢ä»»åŠ¡ï¼ŒåŒ…æ‹¬CVé‡Œçš„è¾¹ç¼˜æ£€æµ‹ï¼Œå›¾åƒåˆ†å‰²ï¼Œè¯­ä¹‰æ ‡ç­¾ä»¥åŠCGé‡Œçš„mapping labels or sparse user inputs to realistic images.

![image-20191124143200833](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092013.png)

è¯¥æ–‡ç« å®šä¹‰äº†$\chi_1$å’Œ$\chi_2$ä½œä¸ºä¸¤ä¸ªå›¾åƒåŸŸ.ä¼ ç»Ÿçš„supervised Image-to-image é€šè¿‡å¯¹å›¾åƒåŸŸè¿›è¡Œé‡‡æ ·,æ±‚å…¶è”åˆæ¦‚ç‡åˆ†å¸ƒ$$P_{(\chi_1,\chi_2)}(x_1,x_2)$$,é€šè¿‡Encoder-Decoderçš„æ€æƒ³,ä½œè€…å®šä¹‰äº†ä¸¤ä¸ªEå’ŒG,å¸Œæœ›ä½¿å¾—z=E(X)åœ¨latent spaceä¸Šè¿‘å¯èƒ½çš„åˆ†å¸ƒä¸€è‡´.æ„å‘³ç€å½“æˆ‘ä»¬åŒæ—¶å¯¹$$Sample(\chi_1 ,\chi_2)$$æ—¶,æˆ‘ä»¬å¸Œæœ›å¾—å‡º:
$$
z=E_{1}^{*}\left(x_{1}\right)=E_{2}^{*}\left(x_{2}\right)
$$

è¿™æ ·,æˆ‘ä»¬å¾—åˆ°äº†ä¸¤ä¸ªDomainä¸‹imageçš„ä¸€è‡´è¡¨ç¤º,å†é€šè¿‡ä»¤$G=D$,ä»latent spaceä¸­é‡æ„$\hat{x}=G(z)$,

å› æ­¤,æˆ‘ä»¬ä¸¤ä¸ªé‡‡æ ·ä¸‹çš„$\{x_1,x_2\}$ç»è¿‡$\{<E_1,G_1>,<E_2,G_1>,<E_1,G_2>,<E_2,G_1>\}$åå¾—åˆ°äº†$\{\hat{x}^{1\rightarrow1}_1,\hat{x}^{2\rightarrow1}_2,\hat{x}^{1\rightarrow2}_1,\hat{x}^{2\rightarrow2}_2\}$,å†æŠŠ:
$$
\hat{x}^{1\rightarrow1}_1,\hat{x}^{2\rightarrow1}_2\rightarrow D_1\rightarrow T/F
$$

$$
\hat{x}^{1\rightarrow2}_1,\hat{x}^{2\rightarrow2}_2\rightarrow D_2\rightarrow T/F
$$

é€šè¿‡Adv_losså¯¹æŠ—å­¦ä¹ è·¨åŸŸç”Ÿæˆå›¾ç‰‡çš„æ•ˆæœ.

å¯èƒ½ç»†å¿ƒçš„ä½ ä»¥åŠå‘ç°äº†è¿™æ˜¯ä¸æ˜¯å¾ˆç±»ä¼¼VAE-GANå—?æ˜¯çš„.

ä½œè€…é€šè¿‡è”åˆè®­ç»ƒ4ä¸ªç½‘ç»œ$VAE_1, VAE_2, GAN_1, GAN_2$çš„ä¸‰ä¸ª$loss function$æ¥è®­ç»ƒæ•´ä¸ªç½‘ç»œ:
$$
\begin{aligned} \min _{E_{1}, E_{2}, G_{1}, G_{2}} \max _{D_{1}, D_{2}} \mathcal{L}_{\mathrm{VAE}_{1}}\left(E_{1}, G_{1}\right)+\mathcal{L}_{\mathrm{GAN}_{1}}\left(E_{2}, G_{1}, D_{1}\right)+\mathcal{L}_{\mathrm{CC}_{1}}\left(E_{1}, G_{1}, E_{2}, G_{2}\right) \\ \mathcal{L}_{\mathrm{VAE}_{2}}\left(E_{2}, G_{2}\right)+\mathcal{L}_{\mathrm{GAN}_{2}}\left(E_{1}, G_{2}, D_{2}\right)+\mathcal{L}_{\mathrm{CC}_{2}}\left(E_{2}, G_{2}, E_{1}, G_{1}\right) \end{aligned}
$$
**VAE**çš„ç›®æ ‡æ˜¯minimize source domain to latent space's KL diversity and latent space to destination domain's KL diversity(æˆ‘è§‰å¾—ä¸­æ–‡å¤ªæ‹—å£äº†,è¿™å¥è¯å®åœ¨æ˜¯è¯´ä¸æ¥)æ¥æœ€å°åŒ–å˜åˆ†ä¸Šç•Œ,VAEçš„å®šä¹‰å¦‚ä¸‹:
$$
\begin{array}{l}{\mathcal{L}_{\mathrm{VAE}_{1}}\left(E_{1}, G_{1}\right)=\lambda_{1} \operatorname{KL}\left(q_{1}\left(z_{1} | x_{1}\right) \| p_{\eta}(z)\right)-\lambda_{2} \mathbb{E}_{z_{1} \sim q_{1}\left(z_{1} | x_{1}\right)}\left[\log p_{G_{1}}\left(x_{1} | z_{1}\right)\right]} \\ {\mathcal{L}_{\mathrm{VAE}_{2}}\left(E_{2}, G_{2}\right)=\lambda_{1} \operatorname{KL}\left(q_{2}\left(z_{2} | x_{2}\right) \| p_{\eta}(z)\right)-\lambda_{2} \mathbb{E}_{z_{2} \sim q_{2}\left(z_{2} | x_{2}\right)}\left[\log p_{G_{2}}\left(x_{2} | z_{2}\right)\right]}\end{array}
$$
**å¯¹æŠ—**:GAN_LOSSè¢«ç”¨äºç¡®ä¿ç¿»è¯‘å›¾åƒç±»ä¼¼å›¾åƒåœ¨ç›®æ ‡åŸŸ.å®šä¹‰å¦‚ä¸‹:
$$
\begin{array}{l}{\mathcal{L}_{\mathrm{GAN}_{1}}\left(E_{2}, G_{1}, D_{1}\right)=\lambda_{0} \mathbb{E}_{x_{1} \sim P_{\mathcal{X}_{1}}}\left[\log D_{1}\left(x_{1}\right)\right]+\lambda_{0} \mathbb{E}_{z_{2} \sim q_{2}\left(z_{2} | x_{2}\right)}\left[\log \left(1-D_{1}\left(G_{1}\left(z_{2}\right)\right)\right)\right]} \\ {\mathcal{L}_{\mathrm{GAN}_{2}}\left(E_{1}, G_{2}, D_{2}\right)=\lambda_{0} \mathbb{E}_{x_{2} \sim P_{\mathcal{X}_{2}}}\left[\log D_{2}\left(x_{2}\right)\right]+\lambda_{0} \mathbb{E}_{z_{1} \sim q_{1}\left(z_{1} | x_{1}\right)}\left[\log \left(1-D_{2}\left(G_{2}\left(z_{1}\right)\right)\right)\right]}\end{array}
$$
**å¾ªç¯ä¸€è‡´æ€§**:ç”±äºshared latent-spaceå‡è®¾æš—å«äº†å¾ªç¯ä¸€è‡´æ€§çº¦æŸï¼Œå› æ­¤æˆ‘ä»¬åœ¨æå‡ºçš„æ¡†æ¶ä¸­å®æ–½å¾ªç¯ä¸€è‡´æ€§çº¦æŸï¼Œä»¥è¿›ä¸€æ­¥è§„èŒƒä¸é€‚å®šçš„æ— ç›‘ç£å›¾åƒé—´è½¬æ¢é—®é¢˜ã€‚äº§ç”Ÿçš„ä¿¡æ¯å¤„ç†æµç§°ä¸ºå¾ªç¯é‡å»ºæµ,å®šä¹‰å¦‚ä¸‹:
$$
\begin{aligned} \mathcal{L}_{\mathrm{CC}_{1}}\left(E_{1}, G_{1}, E_{2}, G_{2}\right)=&\left.\left.\lambda_{3} \operatorname{KL}\left(q_{1}\left(z_{1} | x_{1}\right) \| p_{\eta}(z)\right)+\lambda_{3} \operatorname{KL}\left(q_{2} | x_{1}^{1 \rightarrow 2}\right)\right) \| p_{\eta}(z)\right)-\\ & \lambda_{4} \mathbb{E}_{z_{2} \sim q_{2}\left(z_{2} | x_{1}^{1 \rightarrow 2}\right)}\left[\log p_{G_{1}}\left(x_{1} | z_{2}\right)\right] \\ \mathcal{L}_{\mathrm{CC}_{2}}\left(E_{2}, G_{2}, E_{1}, G_{1}\right)=&\left.\lambda_{3} \operatorname{KL}\left(q_{2}\left(z_{2} | x_{2}\right) \| p_{\eta}(z)\right)+\lambda_{3} \operatorname{KL}\left(q_{1}\left(z_{1} | x_{2}^{2 \rightarrow 1}\right)\right) \| p_{\eta}(z)\right)-\\ & \lambda_{4} \mathbb{E}_{z_{1} \sim q_{1}\left(z_{1} | x_{2}^{2} \rightarrow 1\right)}\left[\log p_{G_{2}}\left(x_{2} | z_{1}\right)\right] \end{aligned}
$$
è®­ç»ƒå¥½çš„ç½‘ç»œ,æˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹latent sapceçš„latent variableé‡ç¼–ç ,è¿›è€ŒæŠŠè¾“å…¥å›¾åƒè¿ç§»åˆ°å„ä¸ªåŸŸä¸­:

![image-20191124154047242](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092023.png)

![image-20191124153813482](https://cy-1256894686.cos.ap-beijing.myqcloud.com/2019-11-24-075358.png)

---

## few-shot

è™½ç„¶UNITä»¥åŠå…¶å˜ç§(cycleGANç­‰ç­‰)å·²ç»è¡¨ç°å¾—éå¸¸æˆåŠŸï¼Œç°æœ‰çš„æ— ç›‘ç£å›¾åƒåˆ°å›¾åƒè½¬æ¢æ¨¡å‹åœ¨ä¸¤ä¸ªæ–¹é¢å—åˆ°é™åˆ¶ã€‚é¦–å…ˆï¼Œå¦‚æœåœ¨è®­ç»ƒæ—¶åªç»™å‡ºå¾ˆå°‘çš„å›¾åƒï¼Œå®ƒä»¬çš„æ ·æœ¬æ•ˆç‡ä½ï¼Œäº§ç”Ÿå·®çš„è½¬æ¢è¾“å‡ºã€‚ 

å…¶æ¬¡ï¼Œå­¦ä¹ çš„æ¨¡å‹ä»…é™äºåœ¨ä¸¤ä¸ªç±»ä¹‹é—´è½¬æ¢å›¾åƒã€‚å°½ç®¡æ–°ä»»åŠ¡ä¸åŸå§‹ä»»åŠ¡ä¹‹é—´å­˜åœ¨ç›¸ä¼¼æ€§ï¼Œä½†æ˜¯ç”¨äºä¸€ä¸ªè½¬æ¢ä»»åŠ¡çš„è®­ç»ƒæ¨¡å‹ä¸èƒ½ç›´æ¥é‡ç”¨äºæ–°ä»»åŠ¡ã€‚

ä¾‹å¦‚ï¼Œå³ä½¿çŒ«ä¸è€è™æœ‰å¾ˆå¤§çš„ç›¸ä¼¼æ€§ï¼Œä¹Ÿä¸èƒ½å°†å“ˆå£«å¥‡ä¸çŒ«çš„è½¬æ¢æ¨¡å‹é‡æ–°ç”¨äºå“ˆå£«å¥‡ ä¸è€è™çš„è½¬æ¢ã€‚

![image-20191124154554577](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092029.png)

åŒæ ·,ä½œè€…é€šè¿‡few-shotå­¦ä¹ å¾—åˆ°çš„å›¾åƒåŒæ ·å¯ä»¥åº”ç”¨äºå°‘æ ·æœ¬åˆ†ç±»,åœ¨Ablation Studyä¸­ä½œè€…åšäº†éå¸¸è¯¦ç»†çš„æ¯”è¾ƒ,è¿›è€ŒéªŒè¯å…¶æœ‰æ•ˆæ€§.

---

### ç®—æ³•æè¿°

å‰æå‡è®¾:ä¸ºäº†è®­ç»ƒ  FUNITï¼Œæˆ‘ä»¬ä½¿ç”¨æ¥è‡ªä¸€ç»„å¯¹è±¡ç±»ï¼ˆä¾‹å¦‚å„ç§åŠ¨ç‰©ç‰©ç§çš„å›¾åƒï¼‰çš„å›¾åƒï¼Œç§°ä¸ºæºç±»ã€‚æˆ‘ä»¬ä¸å‡è®¾ä»»ä½•ä¸¤ä¸ªç±»åˆ«ä¹‹é—´é…å¯¹å›¾åƒçš„å­˜åœ¨.

ä½¿ç”¨æºç±»å›¾åƒæ¥è®­ç»ƒå¤šçº§æ— ç›‘ç£å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢æ¨¡å‹ã€‚

åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸ºæ¨¡å‹æä¾›äº† ä¸€äº›æ¥è‡ªæ–°å¯¹è±¡ç±»çš„å›¾åƒï¼Œç§°ä¸ºç›®æ ‡ç±»ã€‚è¯¥æ¨¡å‹å¿…é¡»åˆ©ç”¨å°‘ æ•°ç›®æ ‡å›¾åƒå°†ä»»ä½•æºç±»å›¾åƒè½¬æ¢ä¸ºç›®æ ‡ç±»çš„åŒç±»å›¾åƒã€‚

æ¡†æ¶ç”±æ¡ä»¶å›¾åƒç”Ÿæˆå™¨ G å’Œå¤šä»»åŠ¡å¯¹æŠ—åˆ¤åˆ«å™¨ D ç»„æˆã€‚å®ƒé‡‡ç”¨ä¸€ä¸ªå›¾åƒä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬çš„ç”Ÿæˆ å™¨ G åŒæ—¶é‡‡ç”¨å†…å®¹å›¾åƒ $x$å’Œä¸€ç»„ç±»åˆ«å›¾åƒK:{$y_1,y_2\dots y_k$}ä½œä¸ºè¾“å…¥,å¹¶é€šè¿‡ç”Ÿæˆå™¨Gäº§ç”Ÿè¾“å‡ºå›¾åƒ:

$$
\hat{x}=G(x,\{y_1,y_2,\dots y_k\})
$$
æˆ‘ä»¬å°† G ç§°ä¸ºå°‘æ ·æœ¬å›¾åƒè½¬æ¢å™¨ã€‚G  å°†è¾“å…¥å†…å®¹å›¾åƒ$x$æ˜ å°„åˆ°è¾“å‡ºå›¾åƒ$\hat{x}$,ä½¿å¾— x çœ‹èµ·æ¥åƒå±äºå¯¹è±¡ç±»$c_y$çš„å›¾åƒï¼Œå¹¶ä¸”$x$å’Œ$\hat{x}$å…·æœ‰çº¹ç†ç»“æ„ä¸Šçš„ç›¸ä¼¼æ€§ã€‚è®¾ $S$ å’Œ $T$ åˆ†åˆ«è¡¨ç¤ºæºç±»é›†å’Œç›®æ ‡ç±»é›†ã€‚è®­ç»ƒæ—¶,$$c_x,c_y\in S \;\;\;and \;\;\; c_x\neq c_y $$ åœ¨æµ‹è¯•æ—¶ï¼ŒG ä»æœªçœ‹åˆ°çš„ç›®æ ‡ç±»$$c\in T$$è·å–ä¸€äº›å›¾åƒä½œä¸ºç±»å›¾åƒï¼Œå¹¶å°†ä»ä»»ä½•æºç±»é‡‡æ ·çš„ å›¾åƒæ˜ å°„åˆ°ç›®æ ‡ç±» $c $   çš„ç±»ä¼¼å›¾åƒã€‚

### å¤šä»»åŠ¡å¯¹æŠ—åˆ¤åˆ«å™¨

åˆ¤åˆ«å™¨ D é€šè¿‡åŒæ—¶è§£å†³å¤šä¸ªå¯¹æŠ—åˆ†ç±»ä»»åŠ¡æ¥è®­ç»ƒã€‚ æ¯ä¸ªä»»åŠ¡æ˜¯äºŒåˆ†ç±»ä»»åŠ¡ï¼Œç¡®å®šè¾“å…¥å›¾åƒæ˜¯æºç±»çš„å®é™…å›¾åƒè¿˜æ¥è‡ª G ç”Ÿæˆçš„è½¬æ¢è¾“å‡º.è¿™ä¸ªå¯¹æŠ—è®­ç»ƒå®é™…ä¸Šæ˜¯ç±»ä¼¼å‰é¢æåˆ°è¿‡çš„,ä¸åœ¨èµ˜è¿°.

---


## æ¡†æ¶è®¾è®¡

![Image From FUNIT_chs](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092032.png)



å°‘æ ·æœ¬å›¾åƒè½¬æ¢å™¨ç”±ä¸‰ä¸ªå­ç½‘ç»œç»„æˆï¼šå†…å®¹ç¼–ç å™¨$E_x$(Content Encoder)ï¼Œ$E_y$ç±»ç¼–ç å™¨(Class Encoder)å’Œ$F_x$è§£ç å™¨(Decoder).
$$
\overline{\mathbf{x}}=F_{x}\left(\mathbf{z}_{x}, \mathbf{z}_{y}\right)=F_{x}\left(E_{x}(\mathbf{x}), E_{y}\left(\left\{\mathbf{y}_{1}, \dots, \mathbf{y}_{K}\right\}\right)\right)
$$
**å†…å®¹ç¼–ç å™¨**ç”±å‡ ä¸ª 2D å·ç§¯å±‚ç»„æˆï¼Œåè·Ÿå‡ ä¸ªResBlockã€‚å®ƒå°†è¾“å…¥å†…å®¹å›¾åƒ x æ˜ å°„åˆ°å†…å®¹æ½œç $z_x$ ï¼Œå…¶ä»£è¡¨ç©ºé—´ç‰¹å¾æ˜ å°„ã€‚

![image-20191124161458061](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092049.png)

```python
class ContentEncoder(nn.Module):
    def __init__(self, downs, n_res, input_dim, dim, norm, activ, pad_type):
        super(ContentEncoder, self).__init__()
        self.model = []
        self.model += [Conv2dBlock(input_dim, dim, 7, 1, 3,
                                   norm=norm,
                                   activation=activ,
                                   pad_type=pad_type)]
        for i in range(downs):
            self.model += [Conv2dBlock(dim, 2 * dim, 4, 2, 1,
                                       norm=norm,
                                       activation=activ,
                                       pad_type=pad_type)]
            dim *= 2
        self.model += [ResBlocks(n_res, dim,
                                 norm=norm,
                                 activation=activ,
                                 pad_type=pad_type)]
        self.model = nn.Sequential(*self.model)
        self.output_dim = dim

    def forward(self, x):
        return self.model(x)

```



**ç±»ç¼–ç å™¨**ç”±å‡ ä¸ª 2D å·ç§¯å±‚ç»„æˆï¼Œåé¢æ˜¯æ ·æœ¬è½´å¹³æ»‘æ“ä½œã€‚å…·ä½“åœ°è¯´ï¼Œå®ƒé¦–å…ˆæ˜ å°„ Kä¸ªç±»åˆ«å›¾åƒ$$\{y_1,y_2,\dots y_k\}$$æ˜ å°„åˆ°ä¸­é—´æ½œåœ¨å‘é‡,ç„¶åè®¡ç®—ä¸­é—´æ½œåœ¨å‘é‡çš„å¹³å‡å€¼ï¼Œä»¥è·å¾—æœ€ç»ˆçš„æ½œç $z_y$ã€‚

![image-20191124162041845](https://cy-1256894686.cos.ap-beijing.myqcloud.com/2019-11-24-090947.png)

```python
class ClassModelEncoder(nn.Module):
    def __init__(self, downs, ind_im, dim, latent_dim, norm, activ, pad_type):
        super(ClassModelEncoder, self).__init__()
        self.model = []
        self.model += [Conv2dBlock(ind_im, dim, 7, 1, 3,
                                   norm=norm,
                                   activation=activ,
                                   pad_type=pad_type)]
        for i in range(2):
            self.model += [Conv2dBlock(dim, 2 * dim, 4, 2, 1,
                                       norm=norm,
                                       activation=activ,
                                       pad_type=pad_type)]
            dim *= 2
        for i in range(downs - 2):
            self.model += [Conv2dBlock(dim, dim, 4, 2, 1,
                                       norm=norm,
                                       activation=activ,
                                       pad_type=pad_type)]
        self.model += [nn.AdaptiveAvgPool2d(1)]
        self.model += [nn.Conv2d(dim, latent_dim, 1, 1, 0)]
        self.model = nn.Sequential(*self.model)
        self.output_dim = dim

    def forward(self, x):
        return self.model(x)

```

**è§£ç å™¨**ç”±å‡ ä¸ªè‡ªé€‚åº”å®ä¾‹æ­£è§„åŒ–ï¼ˆAdaIN)å’Œæ®‹å·®å—Resblockç»„æˆï¼Œåé¢è·Ÿç€ä¸€äº›ä¸Š é‡‡æ ·å· ç§¯å±‚ã€‚ AdaIN æ®‹ä½™ å—æ˜¯ä½¿ç”¨ AdaIN [18]ä½œä¸ºæ­£åˆ™åŒ–å±‚çš„æ®‹ä½™å—ã€‚å¯¹äºæ¯ä¸ªæ ·æœ¬ï¼ŒAdaIN é¦–å…ˆå°†æ¯ä¸ªé€šé“ä¸­æ ·æœ¬çš„æ¿€æ´»å‡½æ•°æ ‡å‡†åŒ–ä¸ºé›¶å‡å€¼å’Œå•ä½æ–¹å·®ã€‚ç„¶åå®ƒä¼šç¼©æ”¾æ¿€æ´»ä½¿ç”¨ä¸€ç»„æ ‡é‡å’Œåç½®ç»„æˆçš„å­¦ä¹ ä»¿å°„å˜æ¢(é€šè¿‡ä¸¤å±‚å…¨è¿æ¥ç½‘ç»œFC,ä½¿ç”¨è‡ªé€‚åº”åœ°è®¡ç®—ä»¿å°„å˜æ¢å‚æ•°)ã€‚

![image-20191124162355095](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092046.png)

```python
class Decoder(nn.Module):
    def __init__(self, ups, n_res, dim, out_dim, res_norm, activ, pad_type):
        super(Decoder, self).__init__()

        self.model = []
        self.model += [ResBlocks(n_res, dim, res_norm,
                                 activ, pad_type=pad_type)]
        for i in range(ups):
            self.model += [nn.Upsample(scale_factor=2),
                           Conv2dBlock(dim, dim // 2, 5, 1, 2,
                                       norm='in',
                                       activation=activ,
                                       pad_type=pad_type)]
            dim //= 2
        self.model += [Conv2dBlock(dim, out_dim, 7, 1, 3,
                                   norm='none',
                                   activation='tanh',
                                   pad_type=pad_type)]
        self.model = nn.Sequential(*self.model)

    def forward(self, x):
        return self.model(x)


class MLP(nn.Module):
    def __init__(self, in_dim, out_dim, dim, n_blk, norm, activ):

        super(MLP, self).__init__()
        self.model = []
        self.model += [LinearBlock(in_dim, dim, norm=norm, activation=activ)]
        for i in range(n_blk - 2):
            self.model += [LinearBlock(dim, dim, norm=norm, activation=activ)]
        self.model += [LinearBlock(dim, out_dim,
                                   norm='none', activation='none')]
        self.model = nn.Sequential(*self.model)

    def forward(self, x):
        return self.model(x.view(x.size(0), -1))
```

ç”Ÿæˆå™¨æ•´ä½“ä»£ç :

```python
class FewShotGen(nn.Module):
    def __init__(self, hp):
        super(FewShotGen, self).__init__()
        nf = hp['nf']
        nf_mlp = hp['nf_mlp']
        down_class = hp['n_downs_class']
        down_content = hp['n_downs_content']
        n_mlp_blks = hp['n_mlp_blks']
        n_res_blks = hp['n_res_blks']
        latent_dim = hp['latent_dim']
        self.enc_class_model = ClassModelEncoder(down_class,
                                                 3,
                                                 nf,
                                                 latent_dim,
                                                 norm='none',
                                                 activ='relu',
                                                 pad_type='reflect')

        self.enc_content = ContentEncoder(down_content,
                                          n_res_blks,
                                          3,
                                          nf,
                                          'in',
                                          activ='relu',
                                          pad_type='reflect')

        self.dec = Decoder(down_content,
                           n_res_blks,
                           self.enc_content.output_dim,
                           3,
                           res_norm='adain',
                           activ='relu',
                           pad_type='reflect')

        self.mlp = MLP(latent_dim,
                       get_num_adain_params(self.dec),
                       nf_mlp,
                       n_mlp_blks,
                       norm='none',
                       activ='relu')

    def forward(self, one_image, model_set):
        # reconstruct an image
        content, model_codes = self.encode(one_image, model_set)
        model_code = torch.mean(model_codes, dim=0).unsqueeze(0)
        images_trans = self.decode(content, model_code)
        return images_trans

    def encode(self, one_image, model_set):
        # extract content code from the input image
        content = self.enc_content(one_image)
        # extract model code from the images in the model set
        class_codes = self.enc_class_model(model_set)
        class_code = torch.mean(class_codes, dim=0).unsqueeze(0)
        return content, class_code

    def decode(self, content, model_code):
        # decode content and style codes to an image
        adain_params = self.mlp(model_code)
        assign_adain_params(adain_params, self.dec)
        images = self.dec(content)
        return images
```

é€šè¿‡ä½¿ç”¨è¿™ç§è½¬æ¢å™¨è®¾è®¡ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä½¿ç”¨å†…å®¹ç¼–ç  å™¨æå–å…·æœ‰ç±»ä¸å˜çš„æ½œåœ¨è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼Œå¯¹è±¡å§¿åŠ¿ï¼‰å¹¶ä½¿ç”¨ç±»ç¼–ç å™¨æå–ç±»ç‰¹å®šçš„æ½œåœ¨è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼Œå¯¹è±¡å¤–è§‚ï¼‰ã€‚é€šè¿‡ç»ç”± AdaIN å±‚å°†ç±»åˆ«æ½œç é¦ˆé€åˆ°è§£ç å™¨ï¼Œæˆ‘ä»¬è®©ç±»å›¾åƒæ§åˆ¶ å…¨å±€å¤–è§‚ï¼ˆä¾‹å¦‚ï¼Œå¯¹è±¡å¤–è§‚ï¼‰ï¼Œè€Œå†…å®¹å›¾åƒç¡®å®šå±€éƒ¨ç»“æ„ï¼ˆä¾‹å¦‚ï¼Œçœ¼ç›çš„ä½ç½®ï¼‰ã€‚

---

### æŸå¤±å‡½æ•°çš„è®¾è®¡

æˆ‘ä»¬é€šè¿‡è§£å†³ç”±ä¸‹å¼ç»™å‡ºçš„æå°æå¤§ä¼˜åŒ–é—®é¢˜æ¥è®­ç»ƒæ‰€æ å‡ºçš„  FUNIT æ¡†æ¶ï¼š
$$
\min _{D} \max _{G} \mathcal{L}_{\mathrm{GAN}}(D, G)+\lambda_{\mathrm{R}} \mathcal{L}_{\mathrm{R}}(G)+\lambda_{\mathrm{F}} \mathcal{L}_{\mathrm{FM}}(G)
$$
å…¶ä¸­$L_{GAN}$, $L_{R}$å’Œ$L_F$åˆ†åˆ«æ˜¯  GAN æŸå¤±ï¼Œå†…å®¹å›¾åƒé‡å»ºæŸå¤±å’Œç‰¹å¾åŒ¹é…æŸå¤±ã€‚

$GAN$**å¯¹æŠ—**æŸå¤±ä»…ä½¿ç”¨ç±»çš„ç›¸åº”äºŒåˆ†ç±»é¢„æµ‹åˆ†æ•°æ¥è®¡ç®—æŸå¤±ã€‚
$$
\begin{aligned} \mathcal{L}_{\mathrm{GAN}}(G, D)=& E_{\mathrm{x}}\left[-\log D^{c_{x}}(\mathrm{x})\right]+\\ & E_{\mathrm{x},\left\{\mathrm{y}_{1}, \ldots, \mathrm{y}_{K}\right\}}\left[\log \left(1-D^{c_{y}}(\overline{\mathrm{x}})\right]\right.\end{aligned}
$$
$L_R$**å†…å®¹é‡å»º**æŸå¤±æœ‰åŠ©äº G å­¦ä¹ è½¬æ¢æ¨¡å‹ã€‚ å…·ä½“åœ°ï¼Œå½“å¯¹è¾“å…¥å†…å®¹å›¾åƒå’Œè¾“å…¥ç±»å›¾åƒä½¿ç”¨ç›¸åŒå›¾åƒæ—¶ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ K = 1ï¼‰ï¼ŒæŸå¤±ä¿ƒä½¿ G ç”Ÿæˆä¸è¾“å…¥ç›¸åŒçš„è¾“å‡ºå›¾åƒ(é‡æ„ä¸€è‡´æ€§,åœ¨cycleGANåœ¨å«identity Loss).
$$
\mathcal{L}_{\mathrm{R}}(G)=E_{\mathrm{x}}\left[\|\mathrm{x}-G(\mathrm{x},\{\mathrm{x}\})\|_{1}^{1}\right]
$$
$L_F$ç‰¹å¾åŒ¹é…æŸå¤±ä½¿è®­ç»ƒæ­£å¸¸åŒ–ã€‚ æˆ‘ä»¬é¦–å…ˆé€šè¿‡ä» D é‡æ–°ç§» åŠ¨æœ€åä¸€ä¸ªï¼ˆé¢„æµ‹ï¼‰å±‚æ¥æ„é€ ä¸€ä¸ªç‰¹å¾æå–å™¨ï¼Œç§°ä¸º$D_f$ ã€‚ ç„¶åæˆ‘ä»¬ä½¿ç”¨ $D_f$ä»è½¬æ¢è¾“å‡º $x$ å’Œ ç±»å›¾åƒ  $\{y_1,y_2\dots y_k\}$ ä¸­æå–ç‰¹å¾å¹¶æœ€å°åŒ– :
$$
\left.\mathcal{L}_{\mathrm{F}}(G)=E_{\mathrm{x},\left\{\mathrm{y}_{1}, \ldots, \mathrm{y}_{K}\right\}}\left[D_{f}(\overline{\mathrm{x}})\right)-\sum_{k} \frac{D_{f}\left(\mathrm{y}_{k}\right)}{K} \|_{1}^{1}\right]
$$

---

### å®éªŒéƒ¨åˆ†

æˆ‘éå¸¸æƒ³é‡ç‚¹è®²ä¸€ä¸‹å®éªŒéƒ¨åˆ†,æˆ‘çœ‹å®Œè¿™ç¯‡æ–‡ç« çš„å®éªŒéƒ¨åˆ†åšçš„å¤ªå¥½äº†,ç»™äº†æˆ‘åœ¨ä»Šåçš„ç§‘ç ”ä¸­ä¸€ä¸ªéå¸¸å¥½çš„æ¦œæ ·.

é‡ç‚¹è¯´ä¸€ä¸‹è¯„ä»·æŒ‡æ ‡å•Š,åœ¨image-to-imageè¿™ä¸ªé¢†åŸŸæ®æˆ‘æ‰€çŸ¥,è‚‰çœ¼è§‚å¯Ÿæ³•æ˜¯æœ€å¥½çš„è¯„ä»·æŒ‡æ ‡,ä½†æ˜¯ä»–ä¹Ÿä¼šå¸¦æ¥ä¸€äº›ä¸ªäººçš„ä¸»è§‚æ€§,æˆ‘ä»¬çœ‹çœ‹ä½œè€…æ˜¯å¦‚ä½•é€šè¿‡å®éªŒè¯´æœæˆ‘çš„:

å…ˆæ”¾ä¸€å¼ æ¼‚äº®çš„å¤§å›¾:

![image-20191124164040054](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092101.png)

æ€§èƒ½æŒ‡æ ‡ã€‚ä½œè€…ä½¿ç”¨å‡ ä¸ªæ ‡å‡†è¿›è¡Œè¯„ä¼°ã€‚é¦–å…ˆï¼Œä½œè€…æµ‹é‡è½¬æ¢æ˜¯å¦ç±»ä¼¼äºç›®æ ‡ç±»çš„å›¾åƒã€‚å…¶æ¬¡ï¼Œä½œè€…æ£€æŸ¥åœ¨è½¬æ¢æœŸé—´æ˜¯å¦ä¿ç•™äº†ç±»ä¸å˜å†…å®¹ã€‚ç¬¬ä¸‰ï¼Œä½œè€…é‡åŒ–è¾“å‡ºå›¾åƒçš„å†™å®ç…§ç‰‡ã€‚æœ€åï¼Œä½œè€…æµ‹é‡è¯¥æ¨¡å‹æ˜¯å¦å¯ç”¨äºç”Ÿæˆç›®æ ‡ç±»çš„å›¾åƒåˆ†å¸ƒã€‚

![image-20191124164918260](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092047.png)

é‡åŒ–å¯¹æ¯”:User performance score(è‚‰çœ¼è§‚å¯Ÿæ³•):

![image-20191124164847559](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092051.png)

å°‘æ ·æœ¬åˆ†ç±»å‡†ç¡®åº¦:

![image-20191124164500507](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092109.png)

![image-20191124164530895](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092107.png)

Inception Score(æˆ‘å¾ˆå›°æƒ‘è¿™ä¸ªæŒ‡æ ‡çœŸçš„æœ‰ç”¨å—?)å’ŒFID(è¿™ä¸ªç¡®å®è¿˜æœ‰ç‚¹ç”¨):

![image-20191124164640897](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092105.png)

#### Ablation Study

(éƒ½èƒ½åšæŒçœ‹åˆ°è¿™é‡Œäº†éƒ½,æˆ‘è§‰å¾—è‹±æ–‡è¯´å¾—æ›´æ˜ç™½äº†ğŸ˜):

we analyze impact of the content image reconstruction loss weight on the Animal Faces dataset.The table shows that Î»R = 0.1 provides a good trade-off, and we used it as the default value throughout the paper. Interestingly, a very small weight value Î»R = 0.01 results in degrading performance on both 
content preservation and translation accuracy. 

![image-20191124165155042](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092110.png)

![image-20191124165220954](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092102.png)

#### Latent Space Interpolation

we use t-SNE to visualize the class code in a two dimensional space. It can be seen that images from similar classes are grouped  together in  the class embedding space.

![image-20191124165306611](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-11-24-092058.png)

we ï¬nd that by interpolating between two source classes (Siamese cat and Tiger) we can sometimes generate a target class (Tabby cat) that the model has never observed. This suggests that the class encoder learns a general class-speciï¬c representa- tion, thus enabling generalization to novel classes.

## æ€»ç»“

è¿™ç¯‡æ–‡ç« å¾ˆå¥½çš„ç»“åˆäº†few-shotè§£å†³UNpair image-to-imageçš„æ ·æœ¬ä¸å‡è¡¡çš„é—®é¢˜,æ›´é‡è¦çš„æ˜¯å…¶åŠå…¶æ¥è¿‘å®é™…çš„ç”Ÿäº§åº”ç”¨ç¯å¢ƒ,æ˜¯ä¸€ç¯‡æ— è®ºæ˜¯ä»ç†è®ºä¸Šè¿˜æ˜¯å®é™…åº”ç”¨è§’åº¦å‡ºå‘æ¥çœ‹,éƒ½å…·æœ‰é‡å¤§æŒ‡å¯¼æ„ä¹‰çš„æ–‡ç« ,ç¬”è€…åŒæ ·å¾ˆå–œæ¬¢è¿™ä¸ªå·¥ä½œ.

å¦‚æœæ‚¨æ˜¯ä¸€ä½C9é«˜æ ¡çš„è€å¸ˆ,çœ‹åˆ°äº†è¿™ç¯‡æ–‡ç« ,å¯ä»¥åœ¨çŸ¥ä¹ä¸Šè”ç³»[æˆ‘](https://www.zhihu.com/people/ba-la-ba-la-82-47/activities),ç¬”è€…ç›®å‰æ­£å°±è¯»äºä¸­å›½æµ·æ´‹å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸š,å‘è¡¨CCF_Cç±»ä¸€ä½œä¸€ç¯‡,SCI_1åŒº3ä½œ,ä¸€ç¯‡æ–‡ç« åœ¨æŠ•,å¸Œæœ›æœ‰å¤§ä½¬æŠŠæˆ‘é¢†èµ°äº†(-â•¹â–½â•¹-).