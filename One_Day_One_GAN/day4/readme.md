# One Day One GAN

Hi ,my name is Chen Yang ,I am a sophomore in ocean university of China .I do some scientific research in my spare time. Based on the current hot direction of artificial intelligence, I hope to share my research progress with **Generative adversarial network**

å—¨ï¼Œæˆ‘çš„åå­—æ˜¯é™ˆæ‰¬ï¼Œæˆ‘æ˜¯ä¸­å›½æµ·æ´‹å¤§å­¦çš„äºŒå¹´çº§å­¦ç”Ÿã€‚æˆ‘åœ¨ä¸šä½™æ—¶é—´åšäº†ä¸€äº›ç§‘å­¦ç ”ç©¶ã€‚åŸºäºå½“å‰äººå·¥æ™ºèƒ½çš„çƒ­ç‚¹æ–¹å‘ï¼Œæˆ‘å¸Œæœ›ä¸**ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåˆ†äº«æˆ‘çš„ç ”ç©¶è¿›å±•**

## å‰è¨€

**ODOG**,é¡¾åæ€ä¹‰å°±æˆ‘æˆ‘å¸Œæœ›èƒ½æ¯å¤©æŠ½å‡ºä¸€ä¸ªå°æ—¶çš„æ—¶é—´æ¥è®²è®²åˆ°ç›®å‰ä¸ºæ­¢,GANçš„å‰æ²¿å‘å±•å’Œç ”ç©¶,ç¬”è€…è§‚å¯Ÿäº†å¾ˆå¤šæ·±åº¦å­¦ä¹ çš„åº”ç”¨,ç‰¹åˆ«æ˜¯åœ¨å›¾åƒè¿™ä¸€æ–¹é¢,GANå·²ç»åœ¨æ‰®æ¼”ç€è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²,æˆ‘ä»¬ç»å¸¸å¯ä»¥çœ‹åˆ°è€é»„çš„NVIDIAåšäº†å„ç§å„æ ·çš„application,è€Œä¸”å…¶ä¸­æ¶‰åŠåˆ°äº†å¤§é‡GANçš„ç†è®ºåŠå…¶å®ç°,å†è€…ç¬”è€…ä¸ªäººä¹Ÿè§‰å¾—ç›®å‰å›½å†…ç¼ºå°‘GANåœ¨pytorch,keras,tensorflowç­‰ä¸»æµçš„æ¡†æ¶ä¸‹çš„å®ç°æ•™å­¦.

æˆ‘çš„è€å¸ˆæ›¾ç»å¯¹æˆ‘è¯´è¿‡:"**æ·±åº¦å­¦ä¹ æ˜¯ä¸€å—æœªçŸ¥çš„æ–°å¤§é™†,å®ƒæ˜¯ä¸€ä¸ªå¤§çš„é»‘ç®±ç³»ç»Ÿ,è€ŒGANåˆ™æ˜¯é»‘ç®±ä¸­çš„é»‘ç®±,è°è¦æ˜¯èƒ½æ‰“å¼€è¿™ä¸ªç›’å­,å°†ä¼šå¼•é¢†ä¸€ä¸ªæ–°çš„æ—¶ä»£**"

### ACGAN

ACGANçš„å…¨ç§°å«Auxiliary Classifier Generative Adversarial Network,ç¿»è¯‘æˆæ±‰è¯­çš„æ„æ€å°±æ˜¯å¸¦è¾…åŠ©åˆ†ç±»å™¨çš„GAN,å…¶å®ä»–çš„æ€æƒ³å’Œæ˜¨å¤©è¯´åˆ°çš„CGANå¾ˆæƒ³,ä¹Ÿæ˜¯åˆ©ç”¨labelçš„ä¿¡æ¯ä½œä¸ºå™ªå£°çš„è¾“å…¥çš„æ¡ä»¶æ¦‚ç‡,ä½†æ˜¯ç›¸æ¯”è¾ƒäºCGAN,ACGANåœ¨è®¾è®¡ä¸Šæ›´ä¸ºå·§å¦™,ä»–å¾ˆå¥½åœ°åˆ©ç”¨äº†åˆ¤åˆ«å™¨ä½¿å¾—ä¸ä½†å¯ä»¥åˆ¤åˆ«çœŸå‡,ä¹Ÿå¯ä»¥åˆ¤åˆ«ç±»åˆ«,é€šè¿‡å¯¹ç”Ÿæˆå›¾åƒç±»åˆ«çš„åˆ¤æ–­,åˆ¤åˆ«å™¨å¯ä»¥æ›´å¥½åœ°ä¼ é€’losså‡½æ•°ä½¿å¾—ç”Ÿæˆå™¨èƒ½å¤Ÿæ›´åŠ å‡†ç¡®åœ°æ‰¾åˆ°labelå¯¹åº”çš„å™ªå£°åˆ†å¸ƒ,é€šè¿‡ä¸‹å›¾å‘Šè¯‰äº†æˆ‘ä»¬ACGANä¸CGANçš„å¼‚åŒä¹‹å¤„.

![image-20190330011810374](https://ws4.sinaimg.cn/large/006tKfTcly1g1k66mb278j31980k0jye.jpg)

ä¸ºæ­¤,æˆ‘ä»¬å…ˆå›é¡¾ä¸€ä¸‹æˆ‘ä»¬æ˜¨å¤©è®²çš„CGANçš„losså‡½æ•°:

![image-20190330012259653](https://ws4.sinaimg.cn/large/006tKfTcly1g1k6bmwocuj31e806qaco.jpg)

é‚£ä¹ˆåœ¨å¯¹æ¯”ä¸€ä¸‹æˆ‘ä»¬ACGANä»–çš„losså‡½æ•°:

![image-20190330012347134](https://ws3.sinaimg.cn/large/006tKfTcly1g1k6cgeiyij30xe06egnv.jpg)

$L_S$è¡¨ç¤ºçš„æ˜¯çœŸå®æ ·æœ¬å¯¹åº”ground truth,å‡çš„æ ·æœ¬å¯¹åº”fake.

$L_c$è¡¨ç¤ºçš„æ˜¯çœŸå®æ ·æœ¬å¯¹åº”ä»–çœŸå®çš„ç±»åˆ«ä¿¡æ¯,å‡çš„æ ·æœ¬å¯¹åº”çš„ä¹Ÿæ˜¯çœŸå®æ ·æœ¬çš„ç±»åˆ«ä¿¡æ¯

**åœ¨è®­ç»ƒåˆ¤åˆ«å™¨çš„æ—¶å€™,æˆ‘ä»¬å¸Œæœ›$L_S+L_C$æœ€å¤§åŒ–**

**åœ¨è®­ç»ƒç”Ÿæˆå™¨çš„æ—¶å€™,æˆ‘ä»¬å¸Œæœ›$L_C-L_S$æœ€å¤§åŒ–**

å½“ç„¶äº†,ä¹Ÿæœ‰äººæ˜¯ä»JSæ•£åº¦ä¼˜åŒ–çš„è§’åº¦æ¥çœ‹å¾…è¿™ä¸ªé—®é¢˜çš„,æˆ‘ä¸æƒ³æŠŠé—®é¢˜å°†å¾—å¤ªå¤æ‚,æœ‰å…´è¶£çš„åŒå­¦å¯ä»¥ç„ä¸€ç„:

![image-20190330013253663](https://ws3.sinaimg.cn/large/006tKfTcly1g1k6lxsfuzj31ao0t27ec.jpg)

### ä»£ç å®ç°

å…¶å®å’Œä¹‹å‰çš„CGAN,åªæ˜¯åšäº†å¾ˆå¾®å°çš„æ”¹å˜,ç”Ÿæˆå™¨å’ŒCGANç›¸æ¯”,å°±æ˜¯åŠ å…¥äº†å·ç§¯å±‚,ç›¸å½“äºæŠŠåŸæ¥CGANé‡Œé¢çš„å¤šå±‚æ„ŸçŸ¥æœºæ¢æˆäº†DCGANé‡Œé¢ä¸€æ ·çš„æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ,é‚£ä¹ˆåˆ¤åˆ«å™¨åŒç†.

#### ç”Ÿæˆå™¨

```python
def build_generator(self):

    model = Sequential()

    model.add(Dense(128 * 7 * 7, activation="relu", input_dim=self.latent_dim))
    model.add(Reshape((7, 7, 128)))
    model.add(BatchNormalization(momentum=0.8))
    model.add(UpSampling2D())
    model.add(Conv2D(128, kernel_size=3, padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(momentum=0.8))
    model.add(UpSampling2D())
    model.add(Conv2D(64, kernel_size=3, padding="same"))
    model.add(Activation("relu"))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Conv2D(self.channels, kernel_size=3, padding='same'))
    model.add(Activation("tanh"))

    model.summary()

    noise = Input(shape=(self.latent_dim,))
    label = Input(shape=(1,), dtype='int32')
    label_embedding = Flatten()(Embedding(self.num_classes, 100)(label))

    model_input = multiply([noise, label_embedding])
    img = model(model_input)

    return Model([noise, label], img)
```

#### åˆ¤åˆ«å™¨

åˆ¤åˆ«å™¨å€’æ˜¯æœ‰äº›æœ‰è¶£,ä»–åœ¨å·ç§¯å±‚çš„æœ«å°¾ç›¸å½“äºåšäº†ä¸€ä¸ªåˆ†å‰,ä¸€è¾¹æ˜¯åˆ¤æ–­çœŸå‡,ä¸€è¾¹æ˜¯è¿˜å¾—åˆ¤æ–­ç±»åˆ«.

```python
def build_discriminator(self):

    model = Sequential()

    model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))
    model.add(Conv2D(32, kernel_size=3, strides=2, padding="same"))
    model.add(ZeroPadding2D(padding=((0,1),(0,1))))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Conv2D(64, kernel_size=3, strides=2, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Conv2D(128, kernel_size=3, strides=1, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.summary()

    img = Input(shape=self.img_shape)

    # Extract feature representation
    features = model(img)

    # Determine validity and label of the image
    validity = Dense(1, activation="sigmoid")(features)
    label = Dense(self.num_classes+1, activation="softmax")(features)

    return Model(img, [validity, label])
#æ‰€ä»¥åˆ¤åˆ«å™¨çš„è¾“å‡ºæœ‰ä¸¤ä¸ª,ä¸€ä¸ªæ˜¯åˆ¤æ–­çœŸå‡çš„validity,ä¸€ä¸ªå›¾ç‰‡å¯¹åº”çš„labelä¿¡æ¯


# å¯¹åº”çš„,ä»–çš„losså‡½æ•°å®šä¹‰ä¹ŸæŒºæœ‰æ„æ€çš„,ä¸å¾—ä¸è¯´kerasæ˜¯çœŸçš„æ–¹ä¾¿ğŸ˜Š 
losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']
self.discriminator = self.build_discriminator()
self.discriminator.compile(loss=losses,
    optimizer=optimizer,
    metrics=['accuracy'])

self.combined = Model([noise, label], [valid, target_label])
self.combined.compile(loss=losses,
    optimizer=optimizer)

```

#### è®­ç»ƒç»†èŠ‚

```python
# ---------------------
#  è®­ç»ƒåˆ¤åˆ«å™¨
# ---------------------

# éšæœºé€‰æ‹©batchä¸ªå›¾ç‰‡
idx = np.random.randint(0, X_train.shape[0], batch_size)
imgs = X_train[idx]

# ç”Ÿæˆé«˜æ–¯å™ªå£°noise
noise = np.random.normal(0, 1, (batch_size, 100))

# ç”Ÿæˆéšæœºæ ‡ç­¾
# image representation of
sampled_labels = np.random.randint(0, 10, (batch_size, 1))

# åº”ç”¨éšæœºæ ‡ç­¾å’Œnoiseç”Ÿæˆå›¾ç‰‡
gen_imgs = self.generator.predict([noise, sampled_labels])

# åˆ¤åˆ«å™¨è¦åˆ¤åˆ«10(0~9)+1(fake)=11ç§ç±»åˆ«
img_labels = y_train[idx]
fake_labels = 10 * np.ones(img_labels.shape)

# è®­ç»ƒåˆ¤åˆ«å™¨
d_loss_real = self.discriminator.train_on_batch(imgs, [valid, img_labels])
d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, fake_labels])
d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

# ---------------------
#  è®­ç»ƒç”Ÿæˆå™¨
# ---------------------

# è®­ç»ƒç”Ÿæˆå™¨
g_loss = self.combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels])

```

### å®éªŒç»“æœ

![image-20190330015005462](https://ws4.sinaimg.cn/large/006tKfTcly1g1k73wcgkij313g0u01l4.jpg)

ä½œè€…ä»1000ç±»çš„imageNetæ•°æ®é›†ä¸ŠæŒ‘é€‰äº†10ç§ç±»åˆ«çš„å›¾åƒ,å¹¶åœ¨ä¸åŒçš„å°ºåº¦ä¸Šåšäº†å®éªŒ,æˆ‘ä»¬çœ‹å¾—å‡ºæ¥,åœ¨å½©è‰²å›¾åƒä¸Šçš„ç”Ÿæˆç»“æœè¿˜æ˜¯é©¬é©¬è™è™ä¸é”™çš„,ä¸è¿‡çœ‹èµ·æ¥è¿˜æ˜¯æ˜¾å¾—å›¾åƒæ²¡ä»€ä¹ˆåè°ƒæ„Ÿ,åœ¨ä¹‹åçš„GANä¸­,æˆ‘ä»¬ä¼šè®²åˆ°å¦‚ä½•åˆ©ç”¨GANç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒ.çœ‹åˆ°è¿™é‡Œäº†è¦æ˜¯çœ‹å®˜è€çˆ·è§‰å¾—interesting,ä¸å¦‚éº»çƒ¦å…³æ³¨è½¬å‘å¥½çœ‹ä¸‰è¿ä¸€æ³¢,ä½ çš„æ¯ä¸€ç‚¹å°å°çš„é¼“åŠ±éƒ½æ˜¯å¯¹ä½œè€…è«å¤§çš„é¼“èˆé¸­ğŸ˜„.

### å‚è€ƒ

<https://zhuanlan.zhihu.com/p/44177576>

<http://ruishu.io/2017/12/26/acgan/>

<https://www.cnblogs.com/punkcure/p/7873566.html>

<https://github.com/eriklindernoren/Keras-GAN/blob/master/acgan/acgan.py>

